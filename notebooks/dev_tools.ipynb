{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a634d671",
   "metadata": {},
   "source": [
    "# SignalFlow Dev Tools\n",
    "\n",
    "Manage your SignalFlow app data directly from VS Code during development.\n",
    "**This is USER mode** - view and update your tickets, checklists, and progress from the app database.\n",
    "\n",
    "**Quick Actions:**\n",
    "- View your sprint tickets with checklists\n",
    "- Update ticket status and checklist items\n",
    "- View release checklist from workflow modes\n",
    "- Manage career progress and test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup - Run this first\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "from src.app.infrastructure.supabase_client import get_client\n",
    "\n",
    "client = get_client()\n",
    "print(f\"‚úÖ Setup complete at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(f\"üìä Supabase: {'Connected' if client else 'Not configured'}\")\n",
    "\n",
    "# Helper to pretty print\n",
    "def pprint(data):\n",
    "    if isinstance(data, (dict, list)):\n",
    "        print(json.dumps(data, indent=2, default=str))\n",
    "    else:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0f79f6",
   "metadata": {},
   "source": [
    "## üìã Sprint Tickets & Checklists\n",
    "View your active sprint tickets with task checklists from the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de6de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sprint Tickets from Database\n",
    "if client:\n",
    "    result = client.table(\"tickets\").select(\n",
    "        \"id, ticket_id, title, status, priority, sprint_points, task_decomposition, tags\"\n",
    "    ).eq(\"in_sprint\", True).order(\"created_at\", desc=True).execute()\n",
    "    \n",
    "    tickets = result.data\n",
    "    print(f\"\\nüìã SPRINT TICKETS ({len(tickets)} active)\\n\" + \"=\"*50)\n",
    "    \n",
    "    for ticket in tickets:\n",
    "        status_icons = {\n",
    "            'done': '‚úÖ', 'in_progress': 'üîÑ', 'in_review': 'üëÅÔ∏è',\n",
    "            'todo': '‚¨ú', 'backlog': 'üìù', 'blocked': 'üö´'\n",
    "        }\n",
    "        icon = status_icons.get(ticket['status'], '‚ùì')\n",
    "        \n",
    "        print(f\"\\n{icon} [{ticket['ticket_id']}] {ticket['title']}\")\n",
    "        print(f\"   Status: {ticket['status']} | Points: {ticket.get('sprint_points', 0)}\")\n",
    "        \n",
    "        # Show task decomposition checklist\n",
    "        if ticket.get('task_decomposition'):\n",
    "            tasks = ticket['task_decomposition']\n",
    "            if isinstance(tasks, str):\n",
    "                tasks = json.loads(tasks)\n",
    "            \n",
    "            print(f\"\\n   üìù Checklist:\")\n",
    "            if isinstance(tasks, list):\n",
    "                for task in tasks:\n",
    "                    if isinstance(task, dict):\n",
    "                        done = task.get('done', task.get('completed', False))\n",
    "                        name = task.get('name', task.get('task', task.get('title', str(task))))\n",
    "                        check = '‚úÖ' if done else '‚¨ú'\n",
    "                        print(f\"      {check} {name}\")\n",
    "                    else:\n",
    "                        print(f\"      ‚¨ú {task}\")\n",
    "            elif isinstance(tasks, dict):\n",
    "                for key, val in tasks.items():\n",
    "                    check = '‚úÖ' if val else '‚¨ú'\n",
    "                    print(f\"      {check} {key}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Supabase not connected - configure SUPABASE_URL and SUPABASE_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3cfb4",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Update Ticket Checklist\n",
    "Mark checklist items as done/undone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5765469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Ticket Checklist Item\n",
    "def update_checklist(ticket_id: str, task_index: int, done: bool):\n",
    "    \"\"\"\n",
    "    Update a checklist item for a ticket.\n",
    "    \n",
    "    Args:\n",
    "        ticket_id: The ticket_id (e.g. \"DEV-123\")\n",
    "        task_index: Index of the task in the checklist (0-based)\n",
    "        done: True to mark complete, False to unmark\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        print(\"‚ö†Ô∏è Supabase not connected\")\n",
    "        return\n",
    "    \n",
    "    # Get current ticket\n",
    "    result = client.table(\"tickets\").select(\"id, task_decomposition\").eq(\"ticket_id\", ticket_id).single().execute()\n",
    "    \n",
    "    if not result.data:\n",
    "        print(f\"‚ùå Ticket {ticket_id} not found\")\n",
    "        return\n",
    "    \n",
    "    tasks = result.data.get('task_decomposition', [])\n",
    "    if isinstance(tasks, str):\n",
    "        tasks = json.loads(tasks)\n",
    "    \n",
    "    if not tasks or task_index >= len(tasks):\n",
    "        print(f\"‚ùå Task index {task_index} out of range\")\n",
    "        return\n",
    "    \n",
    "    # Update the task\n",
    "    if isinstance(tasks[task_index], dict):\n",
    "        tasks[task_index]['done'] = done\n",
    "    else:\n",
    "        tasks[task_index] = {'name': tasks[task_index], 'done': done}\n",
    "    \n",
    "    # Save back\n",
    "    client.table(\"tickets\").update({\n",
    "        \"task_decomposition\": tasks,\n",
    "        \"updated_at\": datetime.now().isoformat()\n",
    "    }).eq(\"id\", result.data['id']).execute()\n",
    "    \n",
    "    status = \"‚úÖ Done\" if done else \"‚¨ú Undone\"\n",
    "    print(f\"{status}: Task {task_index} on {ticket_id}\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# update_checklist(\"DEV-123\", 0, True)  # Mark first item done\n",
    "# update_checklist(\"DEV-123\", 2, False)  # Unmark third item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36379a8",
   "metadata": {},
   "source": [
    "## üß™ Test Cases (from App)\n",
    "View test cases defined in your tickets, not repo pytest files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fcc459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Cases from Ticket Decompositions\n",
    "# Test cases are often embedded in task_decomposition or can be in a separate field\n",
    "\n",
    "if client:\n",
    "    result = client.table(\"tickets\").select(\n",
    "        \"ticket_id, title, task_decomposition, tags\"\n",
    "    ).eq(\"in_sprint\", True).execute()\n",
    "    \n",
    "    print(f\"\\nüß™ TEST CASES FROM TICKETS\\n\" + \"=\"*50)\n",
    "    \n",
    "    for ticket in result.data:\n",
    "        tasks = ticket.get('task_decomposition', [])\n",
    "        if isinstance(tasks, str):\n",
    "            try:\n",
    "                tasks = json.loads(tasks)\n",
    "            except:\n",
    "                tasks = []\n",
    "        \n",
    "        # Look for test-related tasks\n",
    "        test_tasks = []\n",
    "        if isinstance(tasks, list):\n",
    "            for task in tasks:\n",
    "                task_name = task.get('name', str(task)) if isinstance(task, dict) else str(task)\n",
    "                if any(kw in task_name.lower() for kw in ['test', 'verify', 'validate', 'check', 'acceptance', 'qa']):\n",
    "                    test_tasks.append(task)\n",
    "        \n",
    "        # Also check tags for test markers\n",
    "        tags = ticket.get('tags', []) or []\n",
    "        has_test_tag = any('test' in (t or '').lower() for t in tags)\n",
    "        \n",
    "        if test_tasks or has_test_tag:\n",
    "            print(f\"\\nüìã [{ticket['ticket_id']}] {ticket['title']}\")\n",
    "            \n",
    "            for task in test_tasks:\n",
    "                if isinstance(task, dict):\n",
    "                    done = task.get('done', False)\n",
    "                    name = task.get('name', str(task))\n",
    "                else:\n",
    "                    done = False\n",
    "                    name = str(task)\n",
    "                check = '‚úÖ' if done else '‚¨ú'\n",
    "                print(f\"   {check} {name}\")\n",
    "            \n",
    "            if not test_tasks and has_test_tag:\n",
    "                print(\"   ‚ö†Ô∏è Has test tag but no test tasks defined\")\n",
    "    \n",
    "    print(\"\\nüí° Tip: Add test tasks to task_decomposition with 'test', 'verify', or 'acceptance' in the name\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Supabase not connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754a6d0",
   "metadata": {},
   "source": [
    "## üöÄ Release Checklist (from Workflow Modes)\n",
    "View release checklist from the app's workflow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3cb094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Release Checklist from Workflow Modes\n",
    "if client:\n",
    "    # Get workflow modes from database\n",
    "    result = client.table(\"workflow_modes\").select(\n",
    "        \"mode_key, name, icon, steps\"\n",
    "    ).eq(\"is_active\", True).order(\"sort_order\").execute()\n",
    "    \n",
    "    modes = result.data\n",
    "    \n",
    "    # Look for release/deployment related modes\n",
    "    release_mode = None\n",
    "    for mode in modes:\n",
    "        if any(kw in (mode['mode_key'] or '').lower() for kw in ['release', 'deploy', 'ship', 'production']):\n",
    "            release_mode = mode\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nüöÄ RELEASE CHECKLIST\\n\" + \"=\"*50)\n",
    "    \n",
    "    if release_mode:\n",
    "        print(f\"\\n{release_mode.get('icon', 'üöÄ')} {release_mode['name']}\")\n",
    "        steps = release_mode.get('steps', [])\n",
    "        if isinstance(steps, str):\n",
    "            steps = json.loads(steps)\n",
    "        \n",
    "        for step in steps:\n",
    "            if isinstance(step, dict):\n",
    "                name = step.get('label', step.get('name', str(step)))\n",
    "                done = step.get('completed', step.get('done', False))\n",
    "            else:\n",
    "                name = str(step)\n",
    "                done = False\n",
    "            check = '‚úÖ' if done else '‚¨ú'\n",
    "            print(f\"   {check} {name}\")\n",
    "    else:\n",
    "        # Show default release checklist if no mode defined\n",
    "        print(\"\\n‚ö†Ô∏è No release workflow mode found in database\")\n",
    "        print(\"   Creating default checklist...\\n\")\n",
    "        \n",
    "        default_steps = [\n",
    "            \"All tests passing\",\n",
    "            \"Code review complete\",\n",
    "            \"Documentation updated\",\n",
    "            \"Staging verified\",\n",
    "            \"Security scan complete\",\n",
    "            \"Performance check done\",\n",
    "            \"Rollback plan ready\",\n",
    "            \"Stakeholder approval\"\n",
    "        ]\n",
    "        for step in default_steps:\n",
    "            print(f\"   ‚¨ú {step}\")\n",
    "        \n",
    "        print(\"\\nüí° Add a 'release' workflow mode in the app to customize this checklist\")\n",
    "    \n",
    "    # Show all workflow modes available\n",
    "    print(f\"\\n\\nüìÇ Available Workflow Modes:\")\n",
    "    for mode in modes:\n",
    "        print(f\"   {mode.get('icon', 'üìã')} {mode['name']} ({mode['mode_key']})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Supabase not connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Ticket Status\n",
    "def update_ticket_status(ticket_id: str, new_status: str):\n",
    "    \"\"\"\n",
    "    Update a ticket's status.\n",
    "    \n",
    "    Args:\n",
    "        ticket_id: The ticket_id (e.g. \"DEV-123\")\n",
    "        new_status: One of: backlog, todo, in_progress, in_review, blocked, done\n",
    "    \"\"\"\n",
    "    valid_statuses = ['backlog', 'todo', 'in_progress', 'in_review', 'blocked', 'done']\n",
    "    \n",
    "    if new_status not in valid_statuses:\n",
    "        print(f\"‚ùå Invalid status. Use one of: {', '.join(valid_statuses)}\")\n",
    "        return\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ö†Ô∏è Supabase not connected\")\n",
    "        return\n",
    "    \n",
    "    result = client.table(\"tickets\").update({\n",
    "        \"status\": new_status,\n",
    "        \"updated_at\": datetime.now().isoformat()\n",
    "    }).eq(\"ticket_id\", ticket_id).execute()\n",
    "    \n",
    "    if result.data:\n",
    "        icons = {'done': '‚úÖ', 'in_progress': 'üîÑ', 'todo': '‚¨ú', 'blocked': 'üö´'}\n",
    "        icon = icons.get(new_status, 'üìã')\n",
    "        print(f\"{icon} {ticket_id} ‚Üí {new_status}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Ticket {ticket_id} not found\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# update_ticket_status(\"DEV-123\", \"in_progress\")\n",
    "# update_ticket_status(\"DEV-123\", \"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edbf99",
   "metadata": {},
   "source": [
    "## üìä Career Progress & Skill Tracking\n",
    "View your skill development and career memories from the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95851821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Career Data: Skills & Recent Progress\n",
    "if client:\n",
    "    # Get skill tracker data\n",
    "    skills_result = client.table(\"skill_tracker\").select(\n",
    "        \"skill_name, category, proficiency_level, projects_count, tickets_count, last_used_at\"\n",
    "    ).order(\"proficiency_level\", desc=True).limit(15).execute()\n",
    "    \n",
    "    print(f\"\\nüìä TOP SKILLS\\n\" + \"=\"*50)\n",
    "    \n",
    "    for skill in skills_result.data:\n",
    "        level = skill['proficiency_level']\n",
    "        bar = \"‚ñà\" * (level // 10) + \"‚ñë\" * (10 - level // 10)\n",
    "        print(f\"   {skill['skill_name']:20} [{bar}] {level}%\")\n",
    "        if skill.get('projects_count') or skill.get('tickets_count'):\n",
    "            print(f\"   {' '*20}  üìÅ {skill.get('projects_count', 0)} projects, üé´ {skill.get('tickets_count', 0)} tickets\")\n",
    "    \n",
    "    # Get recent career memories\n",
    "    memories_result = client.table(\"career_memories\").select(\n",
    "        \"memory_type, title, skills, created_at\"\n",
    "    ).order(\"created_at\", desc=True).limit(5).execute()\n",
    "    \n",
    "    print(f\"\\n\\nüèÜ RECENT ACHIEVEMENTS\\n\" + \"=\"*50)\n",
    "    \n",
    "    type_icons = {\n",
    "        'completed_project': 'üéØ',\n",
    "        'ai_implementation': 'ü§ñ',\n",
    "        'skill_milestone': 'üìà',\n",
    "        'achievement': 'üèÜ',\n",
    "        'learning': 'üìö'\n",
    "    }\n",
    "    \n",
    "    for memory in memories_result.data:\n",
    "        icon = type_icons.get(memory['memory_type'], 'üìã')\n",
    "        date = memory['created_at'][:10] if memory.get('created_at') else ''\n",
    "        print(f\"   {icon} {memory['title']}\")\n",
    "        if memory.get('skills'):\n",
    "            print(f\"      Skills: {', '.join(memory['skills'][:3])}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Supabase not connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95a76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recent Meetings with Signals\n",
    "if client:\n",
    "    result = client.table(\"meetings\").select(\n",
    "        \"id, meeting_name, meeting_date, signals\"\n",
    "    ).order(\"created_at\", desc=True).limit(5).execute()\n",
    "    \n",
    "    print(f\"\\nüìÖ RECENT MEETINGS\\n\" + \"=\"*50)\n",
    "    \n",
    "    for meeting in result.data:\n",
    "        date = meeting.get('meeting_date', '')[:10] if meeting.get('meeting_date') else 'No date'\n",
    "        print(f\"\\n   üìã {meeting['meeting_name'][:40]}\")\n",
    "        print(f\"      Date: {date}\")\n",
    "        \n",
    "        signals = meeting.get('signals', {})\n",
    "        if isinstance(signals, str):\n",
    "            try:\n",
    "                signals = json.loads(signals)\n",
    "            except:\n",
    "                signals = {}\n",
    "        \n",
    "        if signals:\n",
    "            signal_counts = {}\n",
    "            for sig_type, sig_list in signals.items():\n",
    "                if isinstance(sig_list, list):\n",
    "                    signal_counts[sig_type] = len(sig_list)\n",
    "            \n",
    "            if signal_counts:\n",
    "                counts_str = ', '.join(f\"{v} {k}\" for k, v in signal_counts.items())\n",
    "                print(f\"      Signals: {counts_str}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Supabase not connected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f82ff",
   "metadata": {},
   "source": [
    "## üîß Quick App Actions\n",
    "Update app data without leaving VS Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62decbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Standup Update\n",
    "def add_standup(content: str):\n",
    "    \"\"\"Submit a standup update to the app.\"\"\"\n",
    "    if not client:\n",
    "        print(\"‚ö†Ô∏è Supabase not connected\")\n",
    "        return\n",
    "    \n",
    "    result = client.table(\"standup_updates\").insert({\n",
    "        \"content\": content,\n",
    "        \"sprint_date\": datetime.now().strftime('%Y-%m-%d')\n",
    "    }).execute()\n",
    "    \n",
    "    if result.data:\n",
    "        print(f\"‚úÖ Standup submitted for {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to submit standup\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# add_standup(\"Working on DEV-123 authentication feature. Blocked by API key setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7138544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Career Memory (completed project, AI implementation, etc.)\n",
    "def add_career_memory(\n",
    "    memory_type: str,\n",
    "    title: str,\n",
    "    description: str = None,\n",
    "    skills: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Add a career memory/achievement to track your progress.\n",
    "    \n",
    "    Args:\n",
    "        memory_type: One of: completed_project, ai_implementation, skill_milestone, achievement, learning\n",
    "        title: Short title for the memory\n",
    "        description: Optional longer description\n",
    "        skills: List of skills demonstrated (e.g. [\"Python\", \"FastAPI\", \"OAuth\"])\n",
    "    \"\"\"\n",
    "    valid_types = ['completed_project', 'ai_implementation', 'skill_milestone', 'achievement', 'learning']\n",
    "    \n",
    "    if memory_type not in valid_types:\n",
    "        print(f\"‚ùå Invalid type. Use one of: {', '.join(valid_types)}\")\n",
    "        return\n",
    "    \n",
    "    if not client:\n",
    "        print(\"‚ö†Ô∏è Supabase not connected\")\n",
    "        return\n",
    "    \n",
    "    result = client.table(\"career_memories\").insert({\n",
    "        \"memory_type\": memory_type,\n",
    "        \"title\": title,\n",
    "        \"description\": description,\n",
    "        \"skills\": skills or [],\n",
    "        \"is_ai_work\": memory_type == 'ai_implementation'\n",
    "    }).execute()\n",
    "    \n",
    "    if result.data:\n",
    "        icons = {'completed_project': 'üéØ', 'ai_implementation': 'ü§ñ', 'achievement': 'üèÜ'}\n",
    "        icon = icons.get(memory_type, 'üìã')\n",
    "        print(f\"{icon} Added: {title}\")\n",
    "        if skills:\n",
    "            print(f\"   Skills: {', '.join(skills)}\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to add memory\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# add_career_memory(\"completed_project\", \"OAuth Integration\", skills=[\"OAuth2\", \"FastAPI\", \"Security\"])\n",
    "# add_career_memory(\"ai_implementation\", \"Signal Extraction Pipeline\", skills=[\"LLM\", \"Prompt Engineering\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d354bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Skill Level\n",
    "def update_skill(skill_name: str, level_delta: int = 5, ticket_count_delta: int = 0):\n",
    "    \"\"\"\n",
    "    Update a skill's proficiency level and/or ticket count.\n",
    "    \n",
    "    Args:\n",
    "        skill_name: Name of the skill (e.g. \"Python\", \"FastAPI\")\n",
    "        level_delta: Amount to increase proficiency (0-100 total)\n",
    "        ticket_count_delta: Number of tickets to add to count\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        print(\"‚ö†Ô∏è Supabase not connected\")\n",
    "        return\n",
    "    \n",
    "    # Check if skill exists\n",
    "    existing = client.table(\"skill_tracker\").select(\"id, proficiency_level, tickets_count\").eq(\"skill_name\", skill_name).execute()\n",
    "    \n",
    "    if existing.data:\n",
    "        # Update existing skill\n",
    "        current = existing.data[0]\n",
    "        new_level = min(100, max(0, current['proficiency_level'] + level_delta))\n",
    "        new_tickets = current.get('tickets_count', 0) + ticket_count_delta\n",
    "        \n",
    "        client.table(\"skill_tracker\").update({\n",
    "            \"proficiency_level\": new_level,\n",
    "            \"tickets_count\": new_tickets,\n",
    "            \"last_used_at\": datetime.now().isoformat(),\n",
    "            \"updated_at\": datetime.now().isoformat()\n",
    "        }).eq(\"id\", current['id']).execute()\n",
    "        \n",
    "        print(f\"üìà {skill_name}: {current['proficiency_level']}% ‚Üí {new_level}%\")\n",
    "    else:\n",
    "        # Create new skill\n",
    "        client.table(\"skill_tracker\").insert({\n",
    "            \"skill_name\": skill_name,\n",
    "            \"proficiency_level\": max(0, min(100, level_delta)),\n",
    "            \"tickets_count\": max(0, ticket_count_delta),\n",
    "            \"category\": \"general\",\n",
    "            \"last_used_at\": datetime.now().isoformat()\n",
    "        }).execute()\n",
    "        \n",
    "        print(f\"‚úÖ New skill added: {skill_name} at {level_delta}%\")\n",
    "\n",
    "# Example usage (uncomment to use):\n",
    "# update_skill(\"FastAPI\", level_delta=5, ticket_count_delta=1)\n",
    "# update_skill(\"React Native\", level_delta=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5ea6e",
   "metadata": {},
   "source": [
    "## üîÄ Git & Deployment Status\n",
    "Quick view of git and deployment status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Git Status\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    branch = subprocess.check_output([\"git\", \"branch\", \"--show-current\"], text=True).strip()\n",
    "    status = subprocess.check_output([\"git\", \"status\", \"--porcelain\"], text=True)\n",
    "    \n",
    "    print(f\"\\nüîÄ GIT STATUS\\n\" + \"=\"*50)\n",
    "    print(f\"   Branch: {branch}\")\n",
    "    \n",
    "    if status:\n",
    "        changes = len(status.strip().split('\\n'))\n",
    "        print(f\"   Changes: {changes} files\")\n",
    "        print(f\"\\n{status[:500]}\")\n",
    "    else:\n",
    "        print(\"   Working directory clean ‚úÖ\")\n",
    "        \n",
    "    # Recent commits\n",
    "    log = subprocess.check_output(\n",
    "        [\"git\", \"log\", \"--oneline\", \"-5\"],\n",
    "        text=True\n",
    "    ).strip()\n",
    "    \n",
    "    print(f\"\\n   Recent commits:\")\n",
    "    for line in log.split('\\n'):\n",
    "        print(f\"      {line}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Git error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf285c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Summary Dashboard\n",
    "if client:\n",
    "    print(f\"\\nüìä QUICK SUMMARY\\n\" + \"=\"*50)\n",
    "    \n",
    "    # Tickets summary\n",
    "    tickets = client.table(\"tickets\").select(\"status\").eq(\"in_sprint\", True).execute()\n",
    "    status_counts = {}\n",
    "    for t in tickets.data:\n",
    "        s = t['status']\n",
    "        status_counts[s] = status_counts.get(s, 0) + 1\n",
    "    \n",
    "    print(f\"\\n   üé´ Sprint Tickets:\")\n",
    "    for status, count in sorted(status_counts.items()):\n",
    "        icon = {'done': '‚úÖ', 'in_progress': 'üîÑ', 'todo': '‚¨ú'}.get(status, 'üìã')\n",
    "        print(f\"      {icon} {status}: {count}\")\n",
    "    \n",
    "    # Skills count\n",
    "    skills = client.table(\"skill_tracker\").select(\"id\", count=\"exact\").execute()\n",
    "    print(f\"\\n   üìä Skills tracked: {skills.count}\")\n",
    "    \n",
    "    # Meetings count (this week)\n",
    "    from datetime import timedelta\n",
    "    week_ago = (datetime.now() - timedelta(days=7)).isoformat()\n",
    "    meetings = client.table(\"meetings\").select(\"id\", count=\"exact\").gte(\"created_at\", week_ago).execute()\n",
    "    print(f\"   üìÖ Meetings this week: {meetings.count}\")\n",
    "    \n",
    "    # Career memories\n",
    "    memories = client.table(\"career_memories\").select(\"id\", count=\"exact\").execute()\n",
    "    print(f\"   üèÜ Career memories: {memories.count}\")\n",
    "    \n",
    "    print(f\"\\n   ‚è∞ Updated: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Run setup cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c74fd6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 meetings:\n",
      "  2026-01-26T00:00:00+00:00 | ID: 35a7fde1... | {\"meeting_name\":\"Data Eng Backlog Grooming\",\"synth\n",
      "  2026-01-22T00:00:00+00:00 | ID: 5bcf5731... | {\"meeting_name\":\"Data Eng Backlog Grooming\",\"synth\n",
      "  2026-01-08T00:00:00+00:00 | ID: 1ae18dad... | Data Eng Backlog Grooming\n"
     ]
    }
   ],
   "source": [
    "# 1. Find ALL meetings with 'Data Eng Backlog' in meeting_name\n",
    "meetings_result = supabase.table('meetings').select('id, meeting_name, meeting_date').ilike('meeting_name', '%Data Eng Backlog%').order('meeting_date', desc=True).execute()\n",
    "print(f'Found {len(meetings_result.data)} meetings:')\n",
    "for m in meetings_result.data:\n",
    "    print(f\"  {m['meeting_date']} | ID: {m['id'][:8]}... | {m['meeting_name'][:50]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec9e67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meeting ID: 35a7fde1-ae23-44ba-ae7e-a92fd3ad35cc\n",
      "  Name: Data Eng Backlog Grooming\n",
      "  Date: 2026-01-26\n",
      "\n",
      "Meeting ID: 5bcf5731-fa6b-4505-b0c4-b28f9322181a\n",
      "  Name: Data Eng Backlog Grooming\n",
      "  Date: 2026-01-22\n",
      "\n",
      "Meeting ID: 1ae18dad-9f42-4d83-a742-01650468a20c\n",
      "  Name: Data Eng Backlog Grooming\n",
      "  Date: 2026-01-08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display full meeting data\n",
    "import json\n",
    "meetings_data = []\n",
    "for m in meetings_result.data:\n",
    "    meeting_name = m['meeting_name']\n",
    "    # Check if it's JSON encoded\n",
    "    if isinstance(meeting_name, str) and meeting_name.startswith('{'):\n",
    "        try:\n",
    "            parsed = json.loads(meeting_name)\n",
    "            meeting_name = parsed.get('meeting_name', meeting_name)\n",
    "        except:\n",
    "            pass\n",
    "    meetings_data.append({\n",
    "        'id': m['id'],\n",
    "        'meeting_name': meeting_name,\n",
    "        'meeting_date': m['meeting_date'][:10] if m['meeting_date'] else None\n",
    "    })\n",
    "    print(f\"Meeting ID: {m['id']}\")\n",
    "    print(f\"  Name: {meeting_name}\")\n",
    "    print(f\"  Date: {m['meeting_date'][:10] if m['meeting_date'] else None}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36f0232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 documents:\n",
      "Doc ID: 1b7f70f1-4159-47fc-a43c-883320c9f933\n",
      "  Source: Transcript: Data Eng Backlog Grooming\n",
      "  Doc Date: 2026-01-22\n",
      "  Meeting ID: 5bcf5731-fa6b-4505-b0c4-b28f9322181a\n",
      "\n",
      "Doc ID: 16f6edb8-c58c-43e5-8f8a-0919cd5b995e\n",
      "  Source: Pocket Summary (General Meeting): Data Eng Backlog Grooming\n",
      "  Doc Date: 2026-01-22\n",
      "  Meeting ID: 5bcf5731-fa6b-4505-b0c4-b28f9322181a\n",
      "\n",
      "Doc ID: 68fd56af-1666-421c-99a8-eeafec10719f\n",
      "  Source: Transcript: Data Eng Backlog Grooming\n",
      "  Doc Date: 2026-01-08\n",
      "  Meeting ID: 1ae18dad-9f42-4d83-a742-01650468a20c\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Find ALL documents with 'Data Eng Backlog' in source\n",
    "docs_result = supabase.table('documents').select('id, source, document_date, meeting_id').ilike('source', '%Data Eng Backlog%').order('document_date', desc=True).execute()\n",
    "print(f'Found {len(docs_result.data)} documents:')\n",
    "for d in docs_result.data:\n",
    "    print(f\"Doc ID: {d['id']}\")\n",
    "    print(f\"  Source: {d['source']}\")\n",
    "    print(f\"  Doc Date: {d['document_date'][:10] if d['document_date'] else None}\")\n",
    "    print(f\"  Meeting ID: {d['meeting_id']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8c684e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANALYSIS: Document-Meeting Date Matching\n",
      "============================================================\n",
      "‚úì MATCH\n",
      "  Doc: Transcript: Data Eng Backlog Grooming\n",
      "  Doc Date: 2026-01-22 | Meeting Date: 2026-01-22\n",
      "  Doc ID: 1b7f70f1-4159-47fc-a43c-883320c9f933\n",
      "  Meeting ID: 5bcf5731-fa6b-4505-b0c4-b28f9322181a\n",
      "\n",
      "‚úì MATCH\n",
      "  Doc: Pocket Summary (General Meeting): Data Eng Backlog\n",
      "  Doc Date: 2026-01-22 | Meeting Date: 2026-01-22\n",
      "  Doc ID: 16f6edb8-c58c-43e5-8f8a-0919cd5b995e\n",
      "  Meeting ID: 5bcf5731-fa6b-4505-b0c4-b28f9322181a\n",
      "\n",
      "‚úì MATCH\n",
      "  Doc: Transcript: Data Eng Backlog Grooming\n",
      "  Doc Date: 2026-01-08 | Meeting Date: 2026-01-08\n",
      "  Doc ID: 68fd56af-1666-421c-99a8-eeafec10719f\n",
      "  Meeting ID: 1ae18dad-9f42-4d83-a742-01650468a20c\n",
      "\n",
      "============================================================\n",
      "SUMMARY: 0 mismatches found\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 3. Build mapping and identify mismatches\n",
    "meeting_dates = {m['id']: m['meeting_date'][:10] for m in meetings_result.data if m['meeting_date']}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ANALYSIS: Document-Meeting Date Matching\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mismatches = []\n",
    "for d in docs_result.data:\n",
    "    meeting_id = d['meeting_id']\n",
    "    doc_date = d['document_date'][:10] if d['document_date'] else None\n",
    "    \n",
    "    if meeting_id and meeting_id in meeting_dates:\n",
    "        meeting_date = meeting_dates[meeting_id]\n",
    "        match_status = \"‚úì MATCH\" if doc_date == meeting_date else \"‚úó MISMATCH\"\n",
    "        \n",
    "        print(f\"{match_status}\")\n",
    "        print(f\"  Doc: {d['source'][:50]}\")\n",
    "        print(f\"  Doc Date: {doc_date} | Meeting Date: {meeting_date}\")\n",
    "        print(f\"  Doc ID: {d['id']}\")\n",
    "        print(f\"  Meeting ID: {meeting_id}\")\n",
    "        \n",
    "        if doc_date != meeting_date:\n",
    "            mismatches.append({\n",
    "                'doc_id': d['id'],\n",
    "                'doc_source': d['source'],\n",
    "                'doc_date': doc_date,\n",
    "                'meeting_id': meeting_id,\n",
    "                'meeting_date': meeting_date\n",
    "            })\n",
    "        print()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"SUMMARY: {len(mismatches)} mismatches found\")\n",
    "print(\"=\" * 60)\n",
    "for mm in mismatches:\n",
    "    print(f\"NEEDS FIX: Doc {mm['doc_id']}\")\n",
    "    print(f\"  Doc Date: {mm['doc_date']} ‚Üí should be {mm['meeting_date']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "175b89c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ALL documents attached to 1/8 meeting (1ae18dad-9f42-4d83-a742-01650468a20c):\n",
      "============================================================\n",
      "  Doc ID: 68fd56af-1666-421c-99a8-eeafec10719f\n",
      "  Source: Transcript: Data Eng Backlog Grooming\n",
      "  Date: 2026-01-08\n",
      "\n",
      "Total: 1\n",
      "\n",
      "============================================================\n",
      "ALL documents attached to 1/22 meeting (5bcf5731-fa6b-4505-b0c4-b28f9322181a):\n",
      "============================================================\n",
      "  Doc ID: 1b7f70f1-4159-47fc-a43c-883320c9f933\n",
      "  Source: Transcript: Data Eng Backlog Grooming\n",
      "  Date: 2026-01-22\n",
      "\n",
      "  Doc ID: 16f6edb8-c58c-43e5-8f8a-0919cd5b995e\n",
      "  Source: Pocket Summary (General Meeting): Data Eng Backlog Grooming\n",
      "  Date: 2026-01-22\n",
      "\n",
      "Total: 2\n"
     ]
    }
   ],
   "source": [
    "# 4. Check: Are there ANY documents attached to the 1/8 meeting?\n",
    "jan8_meeting_id = \"1ae18dad-9f42-4d83-a742-01650468a20c\"\n",
    "jan22_meeting_id = \"5bcf5731-fa6b-4505-b0c4-b28f9322181a\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ALL documents attached to 1/8 meeting ({jan8_meeting_id}):\")\n",
    "print(\"=\" * 60)\n",
    "docs_jan8 = supabase.table('documents').select('id, source, document_date').eq('meeting_id', jan8_meeting_id).execute()\n",
    "for d in docs_jan8.data:\n",
    "    print(f\"  Doc ID: {d['id']}\")\n",
    "    print(f\"  Source: {d['source']}\")\n",
    "    print(f\"  Date: {d['document_date'][:10] if d['document_date'] else None}\")\n",
    "    print()\n",
    "print(f\"Total: {len(docs_jan8.data)}\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(f\"ALL documents attached to 1/22 meeting ({jan22_meeting_id}):\")\n",
    "print(\"=\" * 60)\n",
    "docs_jan22 = supabase.table('documents').select('id, source, document_date').eq('meeting_id', jan22_meeting_id).execute()\n",
    "for d in docs_jan22.data:\n",
    "    print(f\"  Doc ID: {d['id']}\")\n",
    "    print(f\"  Source: {d['source']}\")\n",
    "    print(f\"  Date: {d['document_date'][:10] if d['document_date'] else None}\")\n",
    "    print()\n",
    "print(f\"Total: {len(docs_jan22.data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9614fd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ALL documents attached to 1/26 meeting (35a7fde1-ae23-44ba-ae7e-a92fd3ad35cc):\n",
      "============================================================\n",
      "Total: 0\n",
      "\n",
      "============================================================\n",
      "ORPHANED documents (no meeting_id) with Data Eng Backlog:\n",
      "============================================================\n",
      "Total orphaned: 0\n"
     ]
    }
   ],
   "source": [
    "# 5. Check 1/26 meeting (the newest one)\n",
    "jan26_meeting_id = \"35a7fde1-ae23-44ba-ae7e-a92fd3ad35cc\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"ALL documents attached to 1/26 meeting ({jan26_meeting_id}):\")\n",
    "print(\"=\" * 60)\n",
    "docs_jan26 = supabase.table('documents').select('id, source, document_date').eq('meeting_id', jan26_meeting_id).execute()\n",
    "for d in docs_jan26.data:\n",
    "    print(f\"  Doc ID: {d['id']}\")\n",
    "    print(f\"  Source: {d['source']}\")\n",
    "    print(f\"  Date: {d['document_date'][:10] if d['document_date'] else None}\")\n",
    "    print()\n",
    "print(f\"Total: {len(docs_jan26.data)}\")\n",
    "\n",
    "# Also check if there are any orphaned documents with Data Eng Backlog that have no meeting_id\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"ORPHANED documents (no meeting_id) with Data Eng Backlog:\")\n",
    "print(\"=\" * 60)\n",
    "orphaned = supabase.table('documents').select('id, source, document_date, meeting_id').ilike('source', '%Data Eng Backlog%').is_('meeting_id', 'null').execute()\n",
    "for d in orphaned.data:\n",
    "    print(f\"  Doc ID: {d['id']}\")\n",
    "    print(f\"  Source: {d['source']}\")\n",
    "    print(f\"  Date: {d['document_date'][:10] if d['document_date'] else None}\")\n",
    "    print()\n",
    "print(f\"Total orphaned: {len(orphaned.data)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
